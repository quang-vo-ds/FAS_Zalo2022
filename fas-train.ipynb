{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vovanquangnbk/fas-train?scriptVersionId=146595303\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"34130e29","metadata":{"papermill":{"duration":0.005521,"end_time":"2023-10-14T17:09:36.677101","exception":false,"start_time":"2023-10-14T17:09:36.67158","status":"completed"},"tags":[]},"source":["## Set up"]},{"cell_type":"code","execution_count":1,"id":"570bb6b2","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:36.689036Z","iopub.status.busy":"2023-10-14T17:09:36.688618Z","iopub.status.idle":"2023-10-14T17:09:43.007051Z","shell.execute_reply":"2023-10-14T17:09:43.006047Z"},"papermill":{"duration":6.327092,"end_time":"2023-10-14T17:09:43.009268","exception":false,"start_time":"2023-10-14T17:09:36.682176","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from glob import glob\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","import cv2\n","from skimage import io\n","import torch\n","from torch import nn\n","import os\n","from datetime import datetime\n","import time\n","import random\n","import cv2\n","import torchvision\n","from torchvision import transforms\n","import pandas as pd\n","import numpy as np\n","import math\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.data.sampler import SequentialSampler, RandomSampler\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.nn.modules.loss import _WeightedLoss\n","import torch.nn.functional as F\n","from torch.nn import Parameter\n","import torch.utils.model_zoo as model_zoo\n","from torch import nn\n","from torch import optim\n","\n","import sklearn\n","import warnings\n","import joblib\n","from sklearn.metrics import roc_auc_score, log_loss, roc_curve, auc\n","from sklearn import metrics\n","import warnings\n","import cv2"]},{"cell_type":"code","execution_count":2,"id":"3c17c963","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.021041Z","iopub.status.busy":"2023-10-14T17:09:43.020609Z","iopub.status.idle":"2023-10-14T17:09:43.09175Z","shell.execute_reply":"2023-10-14T17:09:43.0906Z"},"papermill":{"duration":0.078937,"end_time":"2023-10-14T17:09:43.093602","exception":false,"start_time":"2023-10-14T17:09:43.014665","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on device: cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Running on device: {device}')"]},{"cell_type":"code","execution_count":3,"id":"bae86545","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.105169Z","iopub.status.busy":"2023-10-14T17:09:43.104894Z","iopub.status.idle":"2023-10-14T17:09:43.109155Z","shell.execute_reply":"2023-10-14T17:09:43.108192Z"},"papermill":{"duration":0.012036,"end_time":"2023-10-14T17:09:43.111033","exception":false,"start_time":"2023-10-14T17:09:43.098997","status":"completed"},"tags":[]},"outputs":[],"source":["data_dir = '/kaggle/input/liveness-detection-zalo-2022/train/train'\n","metadata_dir = os.path.join(data_dir, \"label.csv\")\n","videos_dir = os.path.join(data_dir, \"videos\")"]},{"cell_type":"code","execution_count":4,"id":"18371a09","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.122847Z","iopub.status.busy":"2023-10-14T17:09:43.122295Z","iopub.status.idle":"2023-10-14T17:09:43.127315Z","shell.execute_reply":"2023-10-14T17:09:43.126435Z"},"papermill":{"duration":0.012548,"end_time":"2023-10-14T17:09:43.129048","exception":false,"start_time":"2023-10-14T17:09:43.1165","status":"completed"},"tags":[]},"outputs":[],"source":["CFG = {\n","    'show_examples': False,\n","    'theta': 0.7,\n","    'seed': 719,\n","    'epochs': 15,\n","    'step_size': 5,\n","    'gamma': 0.5,\n","    'train_bs': 16,\n","    'valid_bs': 2,\n","    'lr': 1e-4,\n","    'weight_decay':5e-5,\n","    'num_workers': 2,\n","}"]},{"cell_type":"code","execution_count":5,"id":"98e94c4b","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.140696Z","iopub.status.busy":"2023-10-14T17:09:43.140158Z","iopub.status.idle":"2023-10-14T17:09:43.162223Z","shell.execute_reply":"2023-10-14T17:09:43.161363Z"},"papermill":{"duration":0.029808,"end_time":"2023-10-14T17:09:43.163938","exception":false,"start_time":"2023-10-14T17:09:43.13413","status":"completed"},"tags":[]},"outputs":[],"source":["df = pd.read_csv(metadata_dir)\n","if CFG['show_examples']:\n","    print(df.head())\n","    print(df['liveness_score'].value_counts())"]},{"cell_type":"markdown","id":"e7ea2490","metadata":{"papermill":{"duration":0.004788,"end_time":"2023-10-14T17:09:43.173725","exception":false,"start_time":"2023-10-14T17:09:43.168937","status":"completed"},"tags":[]},"source":["## Utils"]},{"cell_type":"code","execution_count":6,"id":"9551c3b9","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.185274Z","iopub.status.busy":"2023-10-14T17:09:43.184411Z","iopub.status.idle":"2023-10-14T17:09:43.189774Z","shell.execute_reply":"2023-10-14T17:09:43.188968Z"},"papermill":{"duration":0.012835,"end_time":"2023-10-14T17:09:43.191449","exception":false,"start_time":"2023-10-14T17:09:43.178614","status":"completed"},"tags":[]},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True"]},{"cell_type":"markdown","id":"9390eeec","metadata":{"papermill":{"duration":0.004872,"end_time":"2023-10-14T17:09:43.201275","exception":false,"start_time":"2023-10-14T17:09:43.196403","status":"completed"},"tags":[]},"source":["## Train Dataset"]},{"cell_type":"code","execution_count":7,"id":"7c3a83c2","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.212365Z","iopub.status.busy":"2023-10-14T17:09:43.212133Z","iopub.status.idle":"2023-10-14T17:09:43.229545Z","shell.execute_reply":"2023-10-14T17:09:43.228594Z"},"papermill":{"duration":0.025093,"end_time":"2023-10-14T17:09:43.231434","exception":false,"start_time":"2023-10-14T17:09:43.206341","status":"completed"},"tags":[]},"outputs":[],"source":["class RandomErasing(object):\n","    '''\n","    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n","    -------------------------------------------------------------------------------------\n","    probability: The probability that the operation will be performed.\n","    sl: min erasing area\n","    sh: max erasing area\n","    r1: min aspect ratio\n","    mean: erasing value\n","    -------------------------------------------------------------------------------------\n","    '''\n","    def __init__(self, probability = 0.5, sl = 0.01, sh = 0.05, r1 = 0.5, mean=[0.4914, 0.4822, 0.4465]):\n","        self.probability = probability\n","        self.mean = mean\n","        self.sl = sl\n","        self.sh = sh\n","        self.r1 = r1\n","       \n","    def __call__(self, sample):\n","        img, binary_mask, spoofing_label = sample['image_x'], sample['binary_mask'],sample['spoofing_label']\n","        \n","        if random.uniform(0, 1) < self.probability:\n","            attempts = np.random.randint(1, 3)\n","            for attempt in range(attempts):\n","                area = img.shape[0] * img.shape[1]\n","           \n","                target_area = random.uniform(self.sl, self.sh) * area\n","                aspect_ratio = random.uniform(self.r1, 1/self.r1)\n","    \n","                h = int(round(math.sqrt(target_area * aspect_ratio)))\n","                w = int(round(math.sqrt(target_area / aspect_ratio)))\n","    \n","                if w < img.shape[1] and h < img.shape[0]:\n","                    x1 = random.randint(0, img.shape[0] - h)\n","                    y1 = random.randint(0, img.shape[1] - w)\n","\n","                    img[x1:x1+h, y1:y1+w, 0] = self.mean[0]\n","                    img[x1:x1+h, y1:y1+w, 1] = self.mean[1]\n","                    img[x1:x1+h, y1:y1+w, 2] = self.mean[2]\n","                    \n","        return {'image_x': img, 'binary_mask': binary_mask, 'spoofing_label': spoofing_label}\n","\n","\n","# Tensor\n","class Cutout(object):\n","    def __init__(self, length=50):\n","        self.length = length\n","\n","    def __call__(self, sample):\n","        img, binary_mask, spoofing_label = sample['image_x'], sample['binary_mask'],sample['spoofing_label']\n","        h, w = img.shape[1], img.shape[2]    # Tensor [1][2],  nparray [0][1]\n","        mask = np.ones((h, w), np.float32)\n","        y = np.random.randint(h)\n","        x = np.random.randint(w)\n","        length_new = np.random.randint(1, self.length)\n","        \n","        y1 = np.clip(y - length_new // 2, 0, h)\n","        y2 = np.clip(y + length_new // 2, 0, h)\n","        x1 = np.clip(x - length_new // 2, 0, w)\n","        x2 = np.clip(x + length_new // 2, 0, w)\n","\n","        mask[y1: y2, x1: x2] = 0.\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img *= mask\n","        return {'image_x': img, 'binary_mask': binary_mask, 'spoofing_label': spoofing_label}\n","\n","\n","class Normaliztion(object):\n","    \"\"\"\n","        same as mxnet, normalize into [-1, 1]\n","        image = (image - 127.5)/128\n","    \"\"\"\n","    def __call__(self, sample):\n","        image_x, binary_mask, spoofing_label = sample['image_x'], sample['binary_mask'],sample['spoofing_label']\n","        \n","        new_image_x = (image_x - 127.5)/128     # [-1,1]\n","\n","        return {'image_x': new_image_x, 'binary_mask': binary_mask, 'spoofing_label': spoofing_label}\n","\n","\n","class RandomHorizontalFlip(object):\n","    \"\"\"Horizontally flip the given Image randomly with a probability of 0.5.\"\"\"\n","    def __call__(self, sample):\n","        image_x, binary_mask, spoofing_label = sample['image_x'], sample['binary_mask'],sample['spoofing_label']\n","        \n","        new_image_x = np.zeros((256, 256, 3))\n","        new_binary_mask = np.zeros((32, 32))\n","\n","        p = random.random()\n","        if p < 0.5:\n","\n","            new_image_x = cv2.flip(image_x, 1)\n","            new_binary_mask = cv2.flip(binary_mask, 1)\n","           \n","                \n","            return {'image_x': new_image_x, 'binary_mask': new_binary_mask, 'spoofing_label': spoofing_label}\n","        else:\n","            return {'image_x': image_x, 'binary_mask': binary_mask, 'spoofing_label': spoofing_label}\n","\n","\n","\n","class ToTensor(object):\n","    \"\"\"\n","        Convert ndarrays in sample to Tensors.\n","        process only one batch every time\n","    \"\"\"\n","\n","    def __call__(self, sample):\n","        image_x, binary_mask, spoofing_label = sample['image_x'], sample['binary_mask'],sample['spoofing_label']\n","        \n","        # swap color axis because\n","        # numpy image: (batch_size) x H x W x C\n","        # torch image: (batch_size) x C X H X W\n","        image_x = image_x[:,:,::-1].transpose((2, 0, 1))\n","        image_x = np.array(image_x)\n","        \n","        binary_mask = np.array(binary_mask)\n","\n","                        \n","        spoofing_label_np = np.array([0])\n","        spoofing_label_np[0] = spoofing_label\n","        \n","        \n","        return {'image_x': torch.from_numpy(image_x).float(), 'binary_mask': torch.from_numpy(binary_mask).float(), 'spoofing_label': torch.from_numpy(spoofing_label_np).float()}"]},{"cell_type":"code","execution_count":8,"id":"3782757b","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.242283Z","iopub.status.busy":"2023-10-14T17:09:43.242068Z","iopub.status.idle":"2023-10-14T17:09:43.250854Z","shell.execute_reply":"2023-10-14T17:09:43.249988Z"},"papermill":{"duration":0.016217,"end_time":"2023-10-14T17:09:43.252548","exception":false,"start_time":"2023-10-14T17:09:43.236331","status":"completed"},"tags":[]},"outputs":[],"source":["class TrainDataset(Dataset):\n","\n","    def __init__(self, df, root_dir,  transform=None):\n","\n","        self.df = df.copy()\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, idx):\n","        fname = str(self.df.iloc[idx, 0])\n","        v_dir = os.path.join(self.root_dir, fname)\n","    \n","        image_x, binary_mask = self.get_single_image_x(v_dir)\n","        \n","        spoofing_label = self.df.iloc[idx, 1]\n","        if spoofing_label == 1:\n","            spoofing_label = 1            # real\n","        else:\n","            spoofing_label = 0            # fake\n","            binary_mask = np.zeros((32, 32))     \n","\n","        sample = {'image_x': image_x, 'binary_mask': binary_mask, 'spoofing_label': spoofing_label}\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","        return sample\n","\n","    \n","    def get_single_image_x(self, v_dir):\n","        image_x = np.zeros((256, 256, 3))\n","        binary_mask = np.zeros((32, 32))\n","        \n","        ## Pick a random frame\n","        v_cap = cv2.VideoCapture(v_dir)\n","\n","        if v_cap.grab():\n","            v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","            frame_idx = random.randint(0,v_len-1)\n","            v_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n","            _, image_x_temp = v_cap.retrieve()\n","        else:\n","            image_x_temp = np.zeros((256, 256, 3))\n","        v_cap.release()\n","        \n","        image_x_temp_gray = cv2.cvtColor(image_x_temp, cv2.COLOR_BGR2GRAY)\n","\n","        image_x = cv2.resize(image_x_temp, (256, 256))\n","        image_x_temp_gray = cv2.resize(image_x_temp_gray, (32, 32))\n","        \n","        for i in range(32):\n","            for j in range(32):\n","                if image_x_temp_gray[i,j]>0:\n","                    binary_mask[i,j]=1\n","                else:\n","                    binary_mask[i,j]=0\n","        \n","        return image_x, binary_mask"]},{"cell_type":"code","execution_count":9,"id":"be12b193","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.263734Z","iopub.status.busy":"2023-10-14T17:09:43.263023Z","iopub.status.idle":"2023-10-14T17:09:43.268756Z","shell.execute_reply":"2023-10-14T17:09:43.26795Z"},"papermill":{"duration":0.013098,"end_time":"2023-10-14T17:09:43.270493","exception":false,"start_time":"2023-10-14T17:09:43.257395","status":"completed"},"tags":[]},"outputs":[],"source":["# Show examples\n","if CFG['show_examples']:\n","    transform = transforms.Compose([RandomErasing(), RandomHorizontalFlip(),  ToTensor(), Cutout(), Normaliztion()])\n","    dataset = TrainDataset(df, videos_dir, transform)\n","    for i, sample in enumerate(dataset):\n","\n","        print(sample['image_x'].shape)\n","        print(torch.mean(sample['image_x']))\n","        print(sample['binary_mask'].shape)\n","        print(torch.mean(sample['binary_mask']))\n","        print(sample['spoofing_label'])\n","        \n","        if i > 2:\n","            break"]},{"cell_type":"markdown","id":"c6bb9d74","metadata":{"papermill":{"duration":0.004857,"end_time":"2023-10-14T17:09:43.280323","exception":false,"start_time":"2023-10-14T17:09:43.275466","status":"completed"},"tags":[]},"source":["## Val Dataset"]},{"cell_type":"code","execution_count":10,"id":"783c6ae4","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.29179Z","iopub.status.busy":"2023-10-14T17:09:43.291033Z","iopub.status.idle":"2023-10-14T17:09:43.297524Z","shell.execute_reply":"2023-10-14T17:09:43.296986Z"},"papermill":{"duration":0.013909,"end_time":"2023-10-14T17:09:43.299201","exception":false,"start_time":"2023-10-14T17:09:43.285292","status":"completed"},"tags":[]},"outputs":[],"source":["class Normaliztion_valtest(object):\n","    \"\"\"\n","        same as mxnet, normalize into [-1, 1]\n","        image = (image - 127.5)/128\n","    \"\"\"\n","    def __call__(self, sample):\n","        image_x, binary_mask, spoofing_label = sample['image_x'],sample['binary_mask'] ,sample['spoofing_label']\n","        new_image_x = (image_x - 127.5)/128     # [-1,1]\n","        return {'image_x': new_image_x, 'binary_mask': binary_mask , 'spoofing_label': spoofing_label}\n","\n","\n","class ToTensor_valtest(object):\n","    \"\"\"\n","        Convert ndarrays in sample to Tensors.\n","        process only one batch every time\n","    \"\"\"\n","\n","    def __call__(self, sample):\n","        image_x, binary_mask, spoofing_label = sample['image_x'],sample['binary_mask'] ,sample['spoofing_label']\n","        \n","        # swap color axis because    BGR2RGB\n","        # numpy image: (batch_size) x T x H x W x C\n","        # torch image: (batch_size) x T x C X H X W\n","        image_x = image_x[:,:,:,::-1].transpose((0, 3, 1, 2))\n","        image_x = np.array(image_x)\n","        \n","        binary_mask = np.array(binary_mask)\n","                        \n","        spoofing_label_np = np.array([0])\n","        spoofing_label_np[0] = spoofing_label\n","        \n","        return {'image_x': torch.from_numpy(image_x).float(), 'binary_mask': torch.from_numpy(binary_mask).float(),'spoofing_label': torch.from_numpy(spoofing_label_np).long()}"]},{"cell_type":"code","execution_count":11,"id":"7338f40b","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.310584Z","iopub.status.busy":"2023-10-14T17:09:43.309858Z","iopub.status.idle":"2023-10-14T17:09:43.320678Z","shell.execute_reply":"2023-10-14T17:09:43.319897Z"},"papermill":{"duration":0.018205,"end_time":"2023-10-14T17:09:43.322311","exception":false,"start_time":"2023-10-14T17:09:43.304106","status":"completed"},"tags":[]},"outputs":[],"source":["class ValDataset(Dataset):\n","    \n","    def __init__(self, df, root_dir,  transform=None):\n","\n","        self.df = df.copy()\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, idx):\n","\n","        fname = str(self.df.iloc[idx, 0])\n","        v_dir = os.path.join(self.root_dir, fname)\n","    \n","        image_x, binary_mask = self.get_single_image_x(v_dir)\n","        spoofing_label = self.df.iloc[idx, 1]\n","        if spoofing_label == 1:\n","            spoofing_label = 1            # real\n","        else:\n","            spoofing_label = 0            # fake\n","            \n","        sample = {'image_x': image_x, 'binary_mask': binary_mask, 'spoofing_label': spoofing_label}\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","        return sample\n","\n","    def get_single_image_x(self, v_dir):\n","        image_x = np.zeros((256, 256, 3))\n","        binary_mask = np.zeros((32, 32))\n","        \n","        # Extract randomly 3 frams\n","        frames = []\n","        v_cap = cv2.VideoCapture(v_dir)\n","        success = v_cap.grab()\n","        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        fnos = sorted(random.sample(range(v_len), 3))\n","        \n","        # set initial frame \n","        v_cap.set(cv2.CAP_PROP_POS_FRAMES, fnos[0])\n","\n","        pos, count = 0, fnos[0]\n","        while success:\n","            if count == fnos[pos]:\n","                success, frame = v_cap.retrieve()\n","                if not success:               \n","                    break\n","                    \n","                frames.append(frame)\n","                pos += 1\n","                if pos >= len(fnos):\n","                    break\n","\n","            count += 1\n","            success = v_cap.grab()\n","\n","        v_cap.release()\n","        \n","        frames_total = len(frames)\n","        \n","        image_x = np.zeros((frames_total, 256, 256, 3))\n","        binary_mask = np.zeros((frames_total, 32, 32))\n","        \n","        \n","        for ii in range(frames_total):\n","            image_x_temp = frames[ii]\n","            image_x[ii,:,:,:] = cv2.resize(image_x_temp, (256, 256))\n","            \n","            image_x_temp_gray = cv2.cvtColor(image_x_temp, cv2.COLOR_BGR2GRAY)\n","            image_x_temp_gray = cv2.resize(image_x_temp_gray, (32, 32))\n","            \n","            for i in range(32):\n","                for j in range(32):\n","                    if image_x_temp_gray[i,j]>0:\n","                        binary_mask[ii, i, j]=1.0\n","                    else:\n","                        binary_mask[ii, i, j]=0.0\n","            \n","        \n","        return image_x, binary_mask"]},{"cell_type":"code","execution_count":12,"id":"426e96a6","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.333541Z","iopub.status.busy":"2023-10-14T17:09:43.33284Z","iopub.status.idle":"2023-10-14T17:09:43.338394Z","shell.execute_reply":"2023-10-14T17:09:43.337578Z"},"papermill":{"duration":0.012946,"end_time":"2023-10-14T17:09:43.340108","exception":false,"start_time":"2023-10-14T17:09:43.327162","status":"completed"},"tags":[]},"outputs":[],"source":["# Show examples\n","if CFG['show_examples']:\n","    transform = transforms.Compose([Normaliztion_valtest(), ToTensor_valtest()])\n","    dataset = ValDataset(df, videos_dir, transform)\n","    for i, val_sample in enumerate(dataset):\n","        print(val_sample['image_x'].shape)\n","        print(torch.mean(val_sample['image_x']))\n","        print(val_sample['binary_mask'].shape)\n","        print(torch.mean(val_sample['binary_mask']))\n","        print(val_sample['spoofing_label'])\n","        \n","        if i > 1:\n","            break"]},{"cell_type":"markdown","id":"82fe96eb","metadata":{"papermill":{"duration":0.004753,"end_time":"2023-10-14T17:09:43.350123","exception":false,"start_time":"2023-10-14T17:09:43.34537","status":"completed"},"tags":[]},"source":["## Model"]},{"cell_type":"code","execution_count":13,"id":"8d67364f","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.361173Z","iopub.status.busy":"2023-10-14T17:09:43.360934Z","iopub.status.idle":"2023-10-14T17:09:43.380079Z","shell.execute_reply":"2023-10-14T17:09:43.379313Z"},"papermill":{"duration":0.026769,"end_time":"2023-10-14T17:09:43.381759","exception":false,"start_time":"2023-10-14T17:09:43.35499","status":"completed"},"tags":[]},"outputs":[],"source":["############\n","## CDC block\n","############\n","class Conv2d_cd(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n","                 padding=1, dilation=1, groups=1, bias=False, theta=CFG['theta']):\n","\n","        super(Conv2d_cd, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n","        self.theta = theta\n","\n","    def forward(self, x):\n","        out_normal = self.conv(x)\n","\n","        if math.fabs(self.theta - 0.0) < 1e-8:\n","            return out_normal \n","        else:\n","            #pdb.set_trace()\n","            [C_out,C_in, kernel_size,kernel_size] = self.conv.weight.shape\n","            kernel_diff = self.conv.weight.sum(2).sum(2)\n","            kernel_diff = kernel_diff[:, :, None, None]\n","            out_diff = F.conv2d(input=x, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride, padding=0, dilation=self.conv.dilation, groups=self.conv.groups)\n","\n","            return out_normal - self.theta * out_diff\n","\n","############\n","## Attention block\n","############\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel = 3):\n","        super(SpatialAttention, self).__init__()\n","\n","\n","        self.conv1 = nn.Conv2d(2, 1, kernel_size=kernel, padding=kernel//2, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv1(x)\n","        \n","        return self.sigmoid(x)\n","\n","############\n","## CDCN architecture\n","############\n","\n","class CDCN(nn.Module):\n","\n","    def __init__(self, basic_conv=Conv2d_cd, theta=CFG['theta']):   \n","        super(CDCN, self).__init__()\n","        \n","        \n","        self.conv1 = nn.Sequential(\n","            basic_conv(3, 80, kernel_size=3, stride=1, padding=1, bias=False, theta=theta),\n","            nn.BatchNorm2d(80),\n","            nn.ReLU(),    \n","            \n","        )\n","        \n","        self.Block1 = nn.Sequential(\n","            basic_conv(80, 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(),  \n","            \n","            basic_conv(160, int(160*1.6), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(160*1.6)),\n","            nn.ReLU(),  \n","            basic_conv(int(160*1.6), 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(), \n","            \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            \n","        )\n","        \n","        self.Block2 = nn.Sequential(\n","            basic_conv(160, int(160*1.2), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(160*1.2)),\n","            nn.ReLU(),  \n","            basic_conv(int(160*1.2), 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(),  \n","            basic_conv(160, int(160*1.4), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(160*1.4)),\n","            nn.ReLU(),  \n","            basic_conv(int(160*1.4), 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(),  \n","            \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","        )\n","        \n","        self.Block3 = nn.Sequential(\n","            basic_conv(160, 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(), \n","            basic_conv(160, int(160*1.2), kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(int(160*1.2)),\n","            nn.ReLU(),  \n","            basic_conv(int(160*1.2), 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(), \n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","        )\n","        \n","        # Original\n","        \n","        self.lastconv1 = nn.Sequential(\n","            basic_conv(160*3, 160, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.BatchNorm2d(160),\n","            nn.ReLU(),\n","            basic_conv(160, 1, kernel_size=3, stride=1, padding=1, bias=False, theta= theta),\n","            nn.ReLU(),    \n","        )\n","        \n","      \n","        self.sa1 = SpatialAttention(kernel = 7)\n","        self.sa2 = SpatialAttention(kernel = 5)\n","        self.sa3 = SpatialAttention(kernel = 3)\n","        self.downsample32x32 = nn.Upsample(size=(32, 32), mode='bilinear')\n","\n"," \n","    def forward(self, x):\t    \t# x [3, 256, 256]\n","        \n","        x_input = x\n","        x = self.conv1(x)\t\t   \n","        \n","        x_Block1 = self.Block1(x)\t    \t    \t\n","        attention1 = self.sa1(x_Block1)\n","        x_Block1_SA = attention1 * x_Block1\n","        x_Block1_32x32 = self.downsample32x32(x_Block1_SA)   \n","        \n","        x_Block2 = self.Block2(x_Block1)\t    \n","        attention2 = self.sa2(x_Block2)  \n","        x_Block2_SA = attention2 * x_Block2\n","        x_Block2_32x32 = self.downsample32x32(x_Block2_SA)  \n","        \n","        x_Block3 = self.Block3(x_Block2)\t    \n","        attention3 = self.sa3(x_Block3)  \n","        x_Block3_SA = attention3 * x_Block3\t\n","        x_Block3_32x32 = self.downsample32x32(x_Block3_SA)   \n","        \n","        x_concat = torch.cat((x_Block1_32x32,x_Block2_32x32,x_Block3_32x32), dim=1)    \n","        \n","        map_x = self.lastconv1(x_concat)\n","        \n","        map_x = map_x.squeeze(1)\n","        \n","        return map_x, x_concat, attention1, attention2, attention3, x_input"]},{"cell_type":"code","execution_count":14,"id":"0cbe52f3","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.392621Z","iopub.status.busy":"2023-10-14T17:09:43.392398Z","iopub.status.idle":"2023-10-14T17:09:43.396993Z","shell.execute_reply":"2023-10-14T17:09:43.396163Z"},"papermill":{"duration":0.011737,"end_time":"2023-10-14T17:09:43.398592","exception":false,"start_time":"2023-10-14T17:09:43.386855","status":"completed"},"tags":[]},"outputs":[],"source":["# Test dataset\n","if CFG['show_examples']:\n","    model = CDCN(basic_conv=Conv2d_cd, theta=CFG['theta'])\n","    inputs, binary_mask, spoof_label = sample['image_x'], sample['binary_mask'], sample['spoofing_label']\n","    map_x, embedding, x_Block1, x_Block2, x_Block3, x_input =  model(inputs.unsqueeze(0))\n","    print(map_x.shape)\n","    print(map_x)\n","    print(binary_mask.shape)\n","    print(binary_mask)"]},{"cell_type":"markdown","id":"4af79e8b","metadata":{"papermill":{"duration":0.004786,"end_time":"2023-10-14T17:09:43.408283","exception":false,"start_time":"2023-10-14T17:09:43.403497","status":"completed"},"tags":[]},"source":["## Loss"]},{"cell_type":"code","execution_count":15,"id":"3ac4fe10","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.419489Z","iopub.status.busy":"2023-10-14T17:09:43.418821Z","iopub.status.idle":"2023-10-14T17:09:43.426986Z","shell.execute_reply":"2023-10-14T17:09:43.426165Z"},"papermill":{"duration":0.01536,"end_time":"2023-10-14T17:09:43.428605","exception":false,"start_time":"2023-10-14T17:09:43.413245","status":"completed"},"tags":[]},"outputs":[],"source":["def contrast_depth_conv(inputs):\n","    ''' compute contrast depth in both of (out, label) '''\n","    '''\n","        input  32x32\n","        output 8x32x32\n","    '''\n","    \n","\n","    kernel_filter_list =[\n","                        [[1,0,0],[0,-1,0],[0,0,0]], [[0,1,0],[0,-1,0],[0,0,0]], [[0,0,1],[0,-1,0],[0,0,0]],\n","                        [[0,0,0],[1,-1,0],[0,0,0]], [[0,0,0],[0,-1,1],[0,0,0]],\n","                        [[0,0,0],[0,-1,0],[1,0,0]], [[0,0,0],[0,-1,0],[0,1,0]], [[0,0,0],[0,-1,0],[0,0,1]]\n","                        ]\n","    \n","    kernel_filter = np.array(kernel_filter_list, np.float32)\n","    \n","    kernel_filter = torch.from_numpy(kernel_filter).float().to(device)\n","    # weights (in_channel, out_channel, kernel, kernel)\n","    kernel_filter = kernel_filter.unsqueeze(dim=1)\n","    \n","    inputs = inputs.unsqueeze(dim=1).expand(inputs.shape[0], 8, inputs.shape[1],inputs.shape[2])\n","    \n","    contrast_depth = F.conv2d(inputs, weight=kernel_filter, groups=8)  # depthwise conv\n","    \n","    return contrast_depth\n","\n","\n","class Contrast_depth_loss(nn.Module):    # Pearson range [-1, 1] so if < 0, abs|loss| ; if >0, 1- loss\n","    def __init__(self):\n","        super(Contrast_depth_loss,self).__init__()\n","        return\n","    def forward(self, out, label): \n","        '''\n","        compute contrast depth in both of (out, label),\n","        then get the loss of them\n","        tf.atrous_convd match tf-versions: 1.4\n","        '''\n","        contrast_out = contrast_depth_conv(out)\n","        contrast_label = contrast_depth_conv(label)\n","        \n","        criterion_MSE = nn.MSELoss().to(device)\n","    \n","        loss = criterion_MSE(contrast_out, contrast_label)\n","    \n","        return loss"]},{"cell_type":"code","execution_count":16,"id":"072d1c95","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.439684Z","iopub.status.busy":"2023-10-14T17:09:43.438974Z","iopub.status.idle":"2023-10-14T17:09:43.44313Z","shell.execute_reply":"2023-10-14T17:09:43.442212Z"},"papermill":{"duration":0.011381,"end_time":"2023-10-14T17:09:43.44481","exception":false,"start_time":"2023-10-14T17:09:43.433429","status":"completed"},"tags":[]},"outputs":[],"source":["if CFG['show_examples']:\n","    criterion = Contrast_depth_loss()\n","    print(criterion(binary_mask.unsqueeze(0).to(device), map_x.to(device)))"]},{"cell_type":"markdown","id":"56f11770","metadata":{"papermill":{"duration":0.004585,"end_time":"2023-10-14T17:09:43.454301","exception":false,"start_time":"2023-10-14T17:09:43.449716","status":"completed"},"tags":[]},"source":["## Trainer"]},{"cell_type":"code","execution_count":17,"id":"cca4e387","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.465573Z","iopub.status.busy":"2023-10-14T17:09:43.465337Z","iopub.status.idle":"2023-10-14T17:09:43.488914Z","shell.execute_reply":"2023-10-14T17:09:43.488123Z"},"papermill":{"duration":0.031239,"end_time":"2023-10-14T17:09:43.49059","exception":false,"start_time":"2023-10-14T17:09:43.459351","status":"completed"},"tags":[]},"outputs":[],"source":["## Utils\n","class AvgrageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","        \n","    def reset(self):\n","        self.avg = 0\n","        self.sum = 0\n","        self.cnt = 0\n","        \n","    def update(self, val, n=1):\n","        self.sum += val * n\n","        self.cnt += n\n","        self.avg = self.sum / self.cnt\n","\n","def accuracy(output, target, topk=(1,)):\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","    \n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","    \n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0/batch_size))\n","    return res\n","\n","def get_threshold(score_file):\n","    with open(score_file, 'r') as file:\n","        lines = file.readlines()\n","\n","    data = []\n","    count = 0.0\n","    num_real = 0.0\n","    num_fake = 0.0\n","    for line in lines:\n","        count += 1\n","        tokens = line.split()\n","        angle = float(tokens[0])\n","        #pdb.set_trace()\n","        type = int(tokens[1])\n","        data.append({'map_score': angle, 'label': type})\n","        if type==1:\n","            num_real += 1\n","        else:\n","            num_fake += 1\n","\n","    min_error = count    # account ACER (or ACC)\n","    min_threshold = 0.0\n","    min_ACC = 0.0\n","    min_ACER = 0.0\n","    min_APCER = 0.0\n","    min_BPCER = 0.0\n","    \n","    \n","    for d in data:\n","        threshold = d['map_score']\n","        \n","        type1 = len([s for s in data if s['map_score'] <= threshold and s['label'] == 1])\n","        type2 = len([s for s in data if s['map_score'] > threshold and s['label'] == 0])\n","        \n","        ACC = 1-(type1 + type2) / count\n","        APCER = type2 / num_fake\n","        BPCER = type1 / num_real\n","        ACER = (APCER + BPCER) / 2.0\n","        \n","        if ACER < min_error:\n","            min_error = ACER\n","            min_threshold = threshold\n","            min_ACC = ACC\n","            min_ACER = ACER\n","            min_APCER = APCER\n","            min_BPCER = min_BPCER\n","\n","    return min_threshold, min_ACC, min_APCER, min_BPCER, min_ACER\n","\n","\n","\n","def test_threshold_based(threshold, score_file):\n","    with open(score_file, 'r') as file:\n","        lines = file.readlines()\n","\n","    data = []\n","    count = 0.0\n","    num_real = 0.0\n","    num_fake = 0.0\n","    for line in lines:\n","        count += 1\n","        tokens = line.split()\n","        angle = float(tokens[0])\n","        type = int(tokens[1])\n","        data.append({'map_score': angle, 'label': type})\n","        if type==1:\n","            num_real += 1\n","        else:\n","            num_fake += 1\n","    \n"," \n","    type1 = len([s for s in data if s['map_score'] <= threshold and s['label'] == 1])\n","    type2 = len([s for s in data if s['map_score'] > threshold and s['label'] == 0])\n","    \n","    ACC = 1-(type1 + type2) / count\n","    APCER = type2 / num_fake\n","    BPCER = type1 / num_real\n","    ACER = (APCER + BPCER) / 2.0\n","    \n","    return ACC, APCER, BPCER, ACER\n","\n","\n","def get_err_threhold(fpr, tpr, threshold):\n","    RightIndex=(tpr+(1-fpr)-1); \n","    right_index = np.argmax(RightIndex)\n","    best_th = threshold[right_index]\n","    err = fpr[right_index]\n","\n","    differ_tpr_fpr_1=tpr+fpr-1.0\n","  \n","    right_index = np.argmin(np.abs(differ_tpr_fpr_1))\n","    best_th = threshold[right_index]\n","    err = fpr[right_index]    \n","\n","    return err, best_th\n","\n","def performances(map_score_val_filename, map_score_test_filename):\n","\n","    # val \n","    with open(map_score_val_filename, 'r') as file:\n","        lines = file.readlines()\n","    val_scores = []\n","    val_labels = []\n","    data = []\n","    count = 0.0\n","    num_real = 0.0\n","    num_fake = 0.0\n","    for line in lines:\n","        count += 1\n","        tokens = line.split()\n","        score = float(tokens[0])\n","        label = float(tokens[1])  #label = int(tokens[1])\n","        val_scores.append(score)\n","        val_labels.append(label)\n","        data.append({'map_score': score, 'label': label})\n","        if label==1:\n","            num_real += 1\n","        else:\n","            num_fake += 1\n","    \n","    fpr,tpr,threshold = roc_curve(val_labels, val_scores, pos_label=1)\n","    fnr = 1 - tpr\n","    val_err, val_threshold = get_err_threhold(fpr, tpr, threshold)\n","    \n","    type1 = len([s for s in data if s['map_score'] <= val_threshold and s['label'] == 1])\n","    type2 = len([s for s in data if s['map_score'] > val_threshold and s['label'] == 0])\n","    \n","    val_ACC = 1-(type1 + type2) / count\n","    val_APCER = type2 / num_fake\n","    val_BPCER = type1 / num_real\n","    val_ACER = (val_APCER + val_BPCER) / 2.0\n","    \n","    ## EER\n","    eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n","    val_EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n","    \n","    \n","    \n","    # test \n","    with open(map_score_test_filename, 'r') as file2:\n","        lines = file2.readlines()\n","    test_scores = []\n","    test_labels = []\n","    data = []\n","    count = 0.0\n","    num_real = 0.0\n","    num_fake = 0.0\n","    for line in lines:\n","        count += 1\n","        tokens = line.split()\n","        score = float(tokens[0])\n","        label = float(tokens[1])    #label = int(tokens[1])\n","        test_scores.append(score)\n","        test_labels.append(label)\n","        data.append({'map_score': score, 'label': label})\n","        if label==1:\n","            num_real += 1\n","        else:\n","            num_fake += 1\n","    \n","    # test based on val_threshold     \n","    type1 = len([s for s in data if s['map_score'] <= val_threshold and s['label'] == 1])\n","    type2 = len([s for s in data if s['map_score'] > val_threshold and s['label'] == 0])\n","    \n","    test_ACC = 1-(type1 + type2) / max(count,1.0)\n","    test_APCER = type2 / max(num_fake,1.0)\n","    test_BPCER = type1 / max(num_real,1.0)\n","    test_ACER = (test_APCER + test_BPCER) / 2.0\n","    \n","    \n","    # test based on test_threshold     \n","    fpr_test,tpr_test,threshold_test = roc_curve(test_labels, test_scores, pos_label=1)\n","    fnr_test = 1 - tpr_test\n","    err_test, best_test_threshold = get_err_threhold(fpr_test, tpr_test, threshold_test)\n","    \n","    type1 = len([s for s in data if s['map_score'] <= best_test_threshold and s['label'] == 1])\n","    type2 = len([s for s in data if s['map_score'] > best_test_threshold and s['label'] == 0])\n","    \n","    test_threshold_ACC = 1-(type1 + type2) / max(count, 1.0)\n","    test_threshold_APCER = type2 / max(num_fake, 1.0)\n","    test_threshold_BPCER = type1 / max(num_real, 1.0)\n","    test_threshold_ACER = (test_threshold_APCER + test_threshold_BPCER) / 2.0\n","    \n","    ## EER\n","    eer_threshold = threshold_test[np.nanargmin(np.absolute((fnr_test - fpr_test)))]\n","    test_EER = fpr_test[np.nanargmin(np.absolute((fnr_test - fpr_test)))]\n","    \n","    return val_threshold, best_test_threshold, val_ACC, val_ACER, val_EER, test_ACC, test_APCER, test_BPCER, test_ACER, test_threshold_ACER, test_EER"]},{"cell_type":"code","execution_count":18,"id":"46d1a994","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.502048Z","iopub.status.busy":"2023-10-14T17:09:43.501521Z","iopub.status.idle":"2023-10-14T17:09:43.521314Z","shell.execute_reply":"2023-10-14T17:09:43.52052Z"},"papermill":{"duration":0.027505,"end_time":"2023-10-14T17:09:43.523068","exception":false,"start_time":"2023-10-14T17:09:43.495563","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model():\n","    seed_everything(CFG['seed'])\n","    \n","    ## Log file\n","    log_file = open('_log.txt', 'w')\n","\n","    print(\"Liveness Detection Zalo AI 2022:\\n \")\n","\n","    log_file.write('Liveness Detection Zalo AI 2022:\\n ')\n","    log_file.flush()\n","\n","    print('train from scratch!\\n')\n","    log_file.write('train from scratch!\\n')\n","    log_file.flush()\n","    \n","    ## train val test split - use train_test_split twice\n","    train, test = train_test_split(df, test_size=.20)\n","    val, test = train_test_split(test, test_size=.50)\n","    \n","    ## Model\n","    model = CDCN(basic_conv=Conv2d_cd, theta=CFG['theta'])\n","    model = model.to(device)\n","    \n","    ## Optimizer\n","    lr = CFG['lr']\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=CFG['weight_decay'])\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CFG['step_size'], gamma=CFG['gamma'])\n","    \n","    ## Loss function\n","    criterion_absolute_loss = nn.MSELoss().to(device)\n","    criterion_contrastive_loss = Contrast_depth_loss().to(device)\n","    \n","\n","\n","    ACER_save = 1.0\n","    \n","    for epoch in range(CFG['epochs']):  # loop over the dataset multiple times\n","        if (epoch + 1) % CFG['step_size'] == 0:\n","            lr *= CFG['gamma']\n","        \n","        loss_absolute = AvgrageMeter()\n","        loss_contra =  AvgrageMeter()\n","        \n","        ###########################################\n","        '''                train             '''\n","        ###########################################\n","        model.train()\n","        \n","        # train dataloader\n","        train_transform = transforms.Compose([RandomErasing(), RandomHorizontalFlip(),  ToTensor(), Cutout(), Normaliztion()])\n","        train_data = TrainDataset(train, videos_dir, train_transform)\n","        dataloader_train = DataLoader(train_data, batch_size=CFG['train_bs'], shuffle=True, num_workers=CFG['num_workers'])\n","\n","        for i, sample_batched in enumerate(dataloader_train):\n","            # get the inputs\n","            inputs, binary_mask, spoof_label = sample_batched['image_x'].to(device), sample_batched['binary_mask'].to(device), sample_batched['spoofing_label'].to(device)\n","\n","            optimizer.zero_grad()\n","\n","            \n","            # forward + backward + optimize\n","            map_x, embedding, x_Block1, x_Block2, x_Block3, x_input =  model(inputs)\n","            \n","            absolute_loss = criterion_absolute_loss(map_x, binary_mask)\n","            contrastive_loss = criterion_contrastive_loss(map_x, binary_mask)\n","            \n","            loss =  absolute_loss + contrastive_loss\n","             \n","            loss.backward()\n","            \n","            optimizer.step()\n","            \n","            n = inputs.size(0)\n","            loss_absolute.update(absolute_loss.data, n)\n","            loss_contra.update(contrastive_loss.data, n)           \n","        \n","        scheduler.step()\n","        \n","        # whole epoch average\n","        print('epoch:%d, Train:  Absolute_Depth_loss= %.4f, Contrastive_Depth_loss= %.4f\\n' % (epoch + 1, loss_absolute.avg, loss_contra.avg))\n","        log_file.write('epoch:%d, Train: Absolute_Depth_loss= %.4f, Contrastive_Depth_loss= %.4f \\n' % (epoch + 1, loss_absolute.avg, loss_contra.avg))\n","        log_file.flush()\n","           \n","            \n","        epoch_test = 1\n","        if epoch >= 0 and epoch % epoch_test == epoch_test-1:    \n","            model.eval()\n","            \n","            with torch.no_grad():\n","                ###########################################\n","                '''                val             '''\n","                ###########################################\n","                # val for threshold\n","                val_transform = transforms.Compose([Normaliztion_valtest(), ToTensor_valtest()])\n","                val_data = ValDataset(val, videos_dir, val_transform)\n","                dataloader_val = DataLoader(val_data, batch_size=CFG['valid_bs'], shuffle=False, num_workers=CFG['num_workers'])\n","                \n","                map_score_list = []\n","                \n","                for i, sample_batched in enumerate(dataloader_val):\n","                    # get the inputs\n","                    inputs, spoof_label = sample_batched['image_x'].to(device), sample_batched['spoofing_label'].to(device)\n","                    binary_mask = sample_batched['binary_mask'].to(device)\n","        \n","                    optimizer.zero_grad()\n","                    \n","                    \n","                    map_score = 0.0\n","                    for frame_t in range(inputs.shape[1]):\n","                        map_x, embedding, x_Block1, x_Block2, x_Block3, x_input =  model(inputs[:,frame_t,:,:,:].squeeze(dim=1))\n","                        score_norm = torch.mean(map_x)\n","                        map_score += score_norm\n","                    map_score = map_score/inputs.shape[1]\n","                    \n","                    if map_score>1:\n","                        map_score = 1.0\n","    \n","                    map_score_list.append('{} {}\\n'.format(map_score, spoof_label[0][0]))\n","                    \n","                map_score_val_filename = '_map_score_val_%d.txt'% (epoch + 1)\n","                with open(map_score_val_filename, 'w') as file:\n","                    file.writelines(map_score_list) \n","                    \n","                ###########################################\n","                '''                test             '''\n","                ###########################################\n","                # val for threshold\n","                test_transform = transforms.Compose([Normaliztion_valtest(), ToTensor_valtest()])\n","                test_data = ValDataset(test, videos_dir, val_transform)\n","                dataloader_test = DataLoader(test_data, batch_size=CFG['valid_bs'], shuffle=False, num_workers=CFG['num_workers'])\n","                \n","                map_score_list = []\n","                \n","                for i, sample_batched in enumerate(dataloader_test):\n","                    # get the inputs\n","                    inputs, spoof_label = sample_batched['image_x'].to(device), sample_batched['spoofing_label'].to(device)\n","                    binary_mask = sample_batched['binary_mask'].to(device)\n","        \n","                    optimizer.zero_grad()\n","                    \n","                    \n","                    map_score = 0.0\n","                    for frame_t in range(inputs.shape[1]):\n","                        map_x, embedding, x_Block1, x_Block2, x_Block3, x_input =  model(inputs[:,frame_t,:,:,:].squeeze(dim=1))\n","                        score_norm = torch.mean(map_x)\n","                        map_score += score_norm\n","                    map_score = map_score/inputs.shape[1]\n","                    \n","                    if map_score>1:\n","                        map_score = 1.0\n","    \n","                    map_score_list.append('{} {}\\n'.format(map_score, spoof_label[0][0]))\n","                    \n","                map_score_test_filename = '_map_score_test_%d.txt'% (epoch + 1)\n","                with open(map_score_test_filename, 'w') as file:\n","                    file.writelines(map_score_list)\n","                \n","                #############################################################     \n","                #       performance measurement\n","                #############################################################     \n","                val_threshold, best_test_threshold, val_ACC, val_ACER, val_EER, test_ACC, test_APCER, test_BPCER, test_ACER, test_threshold_ACER, test_EER = performances(map_score_val_filename, map_score_test_filename)\n","                \n","                print('epoch:%d, Val:  val_threshold= %.4f, val_ACC= %.4f, val_ACER= %.4f, val_EER= %.4f' % (epoch + 1, val_threshold, val_ACC, val_ACER, val_EER))\n","                log_file.write('\\n epoch:%d, Val:  val_threshold= %.4f, val_ACC= %.4f, val_ACER= %.4f, val_EER= %.4f \\n' % (epoch + 1, val_threshold, val_ACC, val_ACER, val_EER))\n","              \n","                print('epoch:%d, Test:  ACC= %.4f, APCER= %.4f, BPCER= %.4f, ACER= %.4f, EER= %.4f' % (epoch + 1, test_ACC, test_APCER, test_BPCER, test_ACER, test_EER))\n","                print(\"=\"*20)\n","                print('')\n","                log_file.write('epoch:%d, Test:  ACC= %.4f, APCER= %.4f, BPCER= %.4f, ACER= %.4f, EER= %.4f \\n' % (epoch + 1, test_ACC, test_APCER, test_BPCER, test_ACER, test_EER))\n","                \n","                log_file.flush()\n","\n","            \n","            # save the model until the next improvement     \n","            torch.save(model.state_dict(), '_%d.pkl' % (epoch + 1))\n","\n","\n","    print('Finished Training')\n","    log_file.close()"]},{"cell_type":"markdown","id":"3ea72c0c","metadata":{"papermill":{"duration":0.004962,"end_time":"2023-10-14T17:09:43.532924","exception":false,"start_time":"2023-10-14T17:09:43.527962","status":"completed"},"tags":[]},"source":["## Main"]},{"cell_type":"code","execution_count":19,"id":"9880cdb5","metadata":{"execution":{"iopub.execute_input":"2023-10-14T17:09:43.545906Z","iopub.status.busy":"2023-10-14T17:09:43.545607Z","iopub.status.idle":"2023-10-14T19:39:03.533081Z","shell.execute_reply":"2023-10-14T19:39:03.531834Z"},"papermill":{"duration":8960.001856,"end_time":"2023-10-14T19:39:03.541715","exception":false,"start_time":"2023-10-14T17:09:43.539859","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Liveness Detection Zalo AI 2022:\n"," \n","train from scratch!\n","\n","epoch:1, Train:  Absolute_Depth_loss= 0.3567, Contrastive_Depth_loss= 0.0331\n","\n","epoch:1, Val:  val_threshold= 0.3941, val_ACC= 0.5254, val_ACER= 0.4741, val_EER= 0.4643\n","epoch:1, Test:  ACC= 0.5085, APCER= 0.5625, BPCER= 0.4074, ACER= 0.4850, EER= 0.5000\n","====================\n","\n","epoch:2, Train:  Absolute_Depth_loss= 0.2635, Contrastive_Depth_loss= 0.0187\n","\n","epoch:2, Val:  val_threshold= 0.4881, val_ACC= 0.7458, val_ACER= 0.2523, val_EER= 0.2143\n","epoch:2, Test:  ACC= 0.6441, APCER= 0.4688, BPCER= 0.2222, ACER= 0.3455, EER= 0.4062\n","====================\n","\n","epoch:3, Train:  Absolute_Depth_loss= 0.2385, Contrastive_Depth_loss= 0.0088\n","\n","epoch:3, Val:  val_threshold= 0.4900, val_ACC= 0.7288, val_ACER= 0.2702, val_EER= 0.2500\n","epoch:3, Test:  ACC= 0.6441, APCER= 0.5000, BPCER= 0.1852, ACER= 0.3426, EER= 0.3125\n","====================\n","\n","epoch:4, Train:  Absolute_Depth_loss= 0.2285, Contrastive_Depth_loss= 0.0074\n","\n","epoch:4, Val:  val_threshold= 0.5071, val_ACC= 0.6949, val_ACER= 0.3041, val_EER= 0.3214\n","epoch:4, Test:  ACC= 0.6780, APCER= 0.3750, BPCER= 0.2593, ACER= 0.3171, EER= 0.3125\n","====================\n","\n","epoch:5, Train:  Absolute_Depth_loss= 0.2221, Contrastive_Depth_loss= 0.0072\n","\n","epoch:5, Val:  val_threshold= 0.4707, val_ACC= 0.7119, val_ACER= 0.2880, val_EER= 0.3214\n","epoch:5, Test:  ACC= 0.6441, APCER= 0.5000, BPCER= 0.1852, ACER= 0.3426, EER= 0.3125\n","====================\n","\n","epoch:6, Train:  Absolute_Depth_loss= 0.2129, Contrastive_Depth_loss= 0.0067\n","\n","epoch:6, Val:  val_threshold= 0.4843, val_ACC= 0.6949, val_ACER= 0.3041, val_EER= 0.2857\n","epoch:6, Test:  ACC= 0.7119, APCER= 0.3438, BPCER= 0.2222, ACER= 0.2830, EER= 0.1875\n","====================\n","\n","epoch:7, Train:  Absolute_Depth_loss= 0.2082, Contrastive_Depth_loss= 0.0066\n","\n","epoch:7, Val:  val_threshold= 0.4844, val_ACC= 0.7458, val_ACER= 0.2523, val_EER= 0.2143\n","epoch:7, Test:  ACC= 0.7797, APCER= 0.2188, BPCER= 0.2222, ACER= 0.2205, EER= 0.2500\n","====================\n","\n","epoch:8, Train:  Absolute_Depth_loss= 0.2038, Contrastive_Depth_loss= 0.0069\n","\n","epoch:8, Val:  val_threshold= 0.4793, val_ACC= 0.6780, val_ACER= 0.3203, val_EER= 0.3214\n","epoch:8, Test:  ACC= 0.7288, APCER= 0.3438, BPCER= 0.1852, ACER= 0.2645, EER= 0.1875\n","====================\n","\n","epoch:9, Train:  Absolute_Depth_loss= 0.1994, Contrastive_Depth_loss= 0.0069\n","\n","epoch:9, Val:  val_threshold= 0.4976, val_ACC= 0.6610, val_ACER= 0.3381, val_EER= 0.3571\n","epoch:9, Test:  ACC= 0.7797, APCER= 0.2812, BPCER= 0.1481, ACER= 0.2147, EER= 0.1875\n","====================\n","\n","epoch:10, Train:  Absolute_Depth_loss= 0.1912, Contrastive_Depth_loss= 0.0071\n","\n","epoch:10, Val:  val_threshold= 0.4922, val_ACC= 0.7288, val_ACER= 0.2719, val_EER= 0.2857\n","epoch:10, Test:  ACC= 0.7458, APCER= 0.3750, BPCER= 0.1111, ACER= 0.2431, EER= 0.2188\n","====================\n","\n","epoch:11, Train:  Absolute_Depth_loss= 0.1873, Contrastive_Depth_loss= 0.0072\n","\n","epoch:11, Val:  val_threshold= 0.4710, val_ACC= 0.7288, val_ACER= 0.2719, val_EER= 0.2857\n","epoch:11, Test:  ACC= 0.8305, APCER= 0.2188, BPCER= 0.1111, ACER= 0.1649, EER= 0.1562\n","====================\n","\n","epoch:12, Train:  Absolute_Depth_loss= 0.1823, Contrastive_Depth_loss= 0.0070\n","\n","epoch:12, Val:  val_threshold= 0.4923, val_ACC= 0.6949, val_ACER= 0.3041, val_EER= 0.3214\n","epoch:12, Test:  ACC= 0.7966, APCER= 0.2812, BPCER= 0.1111, ACER= 0.1962, EER= 0.1875\n","====================\n","\n","epoch:13, Train:  Absolute_Depth_loss= 0.1769, Contrastive_Depth_loss= 0.0075\n","\n","epoch:13, Val:  val_threshold= 0.4741, val_ACC= 0.6780, val_ACER= 0.3203, val_EER= 0.3214\n","epoch:13, Test:  ACC= 0.8305, APCER= 0.2500, BPCER= 0.0741, ACER= 0.1620, EER= 0.1875\n","====================\n","\n","epoch:14, Train:  Absolute_Depth_loss= 0.1757, Contrastive_Depth_loss= 0.0071\n","\n","epoch:14, Val:  val_threshold= 0.5418, val_ACC= 0.6949, val_ACER= 0.3041, val_EER= 0.2857\n","epoch:14, Test:  ACC= 0.8136, APCER= 0.1875, BPCER= 0.1852, ACER= 0.1863, EER= 0.1875\n","====================\n","\n","epoch:15, Train:  Absolute_Depth_loss= 0.1741, Contrastive_Depth_loss= 0.0073\n","\n","epoch:15, Val:  val_threshold= 0.5292, val_ACC= 0.6949, val_ACER= 0.3041, val_EER= 0.2857\n","epoch:15, Test:  ACC= 0.7966, APCER= 0.1875, BPCER= 0.2222, ACER= 0.2049, EER= 0.1875\n","====================\n","\n","Finished Training\n"]}],"source":["if __name__ == \"__main__\":\n","    train_model()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":8972.264607,"end_time":"2023-10-14T19:39:05.778803","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-14T17:09:33.514196","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}